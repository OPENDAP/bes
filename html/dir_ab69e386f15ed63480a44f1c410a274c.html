<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>bes: data Directory Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">bes<span id="projectnumber">&#160;Updated for version 3.21.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',false,false,'search.php','Search',true);
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dir_ab69e386f15ed63480a44f1c410a274c.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle"><div class="title">data Directory Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Directory dependency graph for data:</div>
<div class="dyncontent">
<div class="center"><img src="dir_ab69e386f15ed63480a44f1c410a274c_dep.png" border="0" usemap="#adir__ab69e386f15ed63480a44f1c410a274c__dep" alt="data"/></div>
<map name="adir__ab69e386f15ed63480a44f1c410a274c__dep" id="adir__ab69e386f15ed63480a44f1c410a274c__dep">
<area shape="rect" href="dir_ab69e386f15ed63480a44f1c410a274c.html" title="data" alt="" coords="47,52,95,77"/>
<area shape="rect" href="dir_8b1b1558f3f6c1ce351d5be39681f4ac.html" title="dmrpp_module" alt="" coords="16,16,127,88"/>
</map>
</div>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>This directory (<em>data</em>) contains:</p><ul>
<li>module test data</li>
<li>The <em>dmr++</em> tools: scripts, source code, and production rules for tools that can be used to create and process <code>hdf5</code>/<code>netcdf-4</code> data files to create portable <em>dmr++</em> files whose binary data objects are held in a web object store like AWS S3.</li>
</ul>
<h1><a class="anchor" id="autotoc_md4"></a>
Overview</h1>
<p>We have developed an initial set of tools that enable a data provider to easily serve data stored in Amazon's S3 Web Object Store. In the current implementation, the data must be stored in HDF5 or NetCDF4 files. The data do not, however, have to be reformatted to be used with the Hyrax server. Furthermore, the data objects are subset 'in-place' from S3 instead of first transferring the object and then serving it, resulting in lower response latency than other solutions for S3 darta access such as those based on FUSE filesystems. For data users, access is seamless - there is no difference between access to data stored in S3 or on spinning disk.</p>
<p>We have conducted tests of this software and the Google Cloud Store and found that it works with that Web Object Store as well. In fact, reconfiguration to GCS is trivial.</p>
<h2><a class="anchor" id="autotoc_md5"></a>
dmr++</h2>
<p>The <em>dmr++</em> files are the control data used by the server to enable 'in-place' access and subsetting of data in S3.</p>
<p><b>self-contained and portable</b>: The <em>dmr++</em> files are self contained. They can be served by any Hyrax server (version 1.16.0 or higher) simply by placing them in the server's data file system.</p>
<p><b>size</b>: The <em>dmr++</em> files are typically very much smaller than their source <code>hdf5</code>/<code>nectdf-4</code> files, by as much as 2 or even 3 orders of magnitude (YMMV).</p>
<h1><a class="anchor" id="autotoc_md6"></a>
dmr++ tools</h1>
<p>There are three programs for building <em>dmr++</em> files:</p><ul>
<li>The program <code>get_dmrpp</code> builds a single <em>dmr++</em> file from a single <code>netcdf-4</code>/<code>hdf5</code> file.</li>
<li>The program <code>ingest_filesystem</code> builds a collection of <em>dmr++</em> files from data held in the locally mounted filesystem.</li>
<li>The program <code>ingest3bucket</code> builds a collection of <em>dmr++</em> files from data held in Amazon's S3 storage.</li>
</ul>
<p>NOTE: Organizationally, this directory (<em>data</em>) and it's child directory <em>dmrpp</em> are arranged in this hierarchy in order to mimic the deployment structure resulting from running "make install". Most modules do not need to do this but since <em>dmr++</em> files reference other files, and they do so using relative paths, the BES Catalog Root the mimicry is required.</p>
<p>NOTE: Examples can be run as shown from the <em>bes/modules/dmrpp___module/data</em> directory.</p>
<h1><a class="anchor" id="autotoc_md7"></a>
building the software</h1>
<p>In order for these programs (shell scripts) to function correctly a localization step must take place. This happens when the parent software (the <code>dmrpp_module</code>) is built and installed as part of the BES. Once this is done the scripts will have been installed and should be in <code>$prefix/bin</code> and ready to use.</p>
<h1><a class="anchor" id="autotoc_md8"></a>
<code>get_dmrpp</code> - build a <em>dmr++</em> file from an <em>hdf5</em>/_nectdf-4_ file.</h1>
<p>The <code>get_dmrpp</code> shell script generates a single <em>dmr++</em> file from a single netcdf-4/hdf5 file. It is used by both <code>ingest_filesystem</code> and <code>ingest_s3bucket</code>.</p>
<div class="fragment"><div class="line">Usage: get_dmrpp [options] &lt;hdf5_file&gt;</div>
<div class="line"> </div>
<div class="line">Write the DMR++ for hdf5_file to stdout</div>
<div class="line"> </div>
<div class="line">By default the BES Data Root directory is set to the CWD. This </div>
<div class="line">utility will add an entry to the bes.log specified in the </div>
<div class="line">configuration file. The DMR++ is built using the DMR as returned </div>
<div class="line">by the HDF5 handler, using options as set in the bes </div>
<div class="line">configuration file found here.</div>
<div class="line"> </div>
<div class="line">-h: Show help</div>
<div class="line">-v: Verbose: Print the DMR too</div>
<div class="line">-V: Very Verbose: print the DMR, the command and the configuration</div>
<div class="line">    file used to build the DMR</div>
<div class="line">-r: Just print the DMR that will be used to build the DMR++</div>
<div class="line">-u: The binary object URL for use in the DMR++ file</div>
<div class="line">-d: Data root directory for the BES.</div>
<div class="line">-o: The name of the file  to create.</div>
<div class="line"> </div>
<div class="line">Limitations: </div>
<div class="line">* The pathanme to the hdf5 file must be relative from the</div>
<div class="line">  directory where this command was run; absolute paths will not work. </div>
<div class="line">* The build_dmrpp command must be in the CWD. </div>
<div class="line">* The bes conf template has to build by hand. jhrg 5/11/18</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md9"></a>
example 1</h2>
<p>Creates a <em>dmr++</em> file (<em>foo.dmrpp</em>) whose binary object URL is a file URL containing the fully qualifed path to the source data file as it's value.</p>
<div class="fragment"><div class="line">get_dmrpp -v -d `pwd` -o foo.dmrpp -u file://`pwd`/dmrpp/chunked_shuffled_fourD.h5 dmrpp/chunked_shuffled_fourD.h5</div>
</div><!-- fragment --> <dl>
<dt><code>-v</code> </dt>
<dd><em>verbose mode</em> </dd>
<dt><code>-d <code>pwd</code></code> </dt>
<dd><em>The data root directory to be used by the BES. In this example it is set to the current directory.</em> </dd>
<dt><code>-o foo.dmrpp</code> </dt>
<dd><em>The dmr++ content will be written to the file foo.dmrpp&lt;</em> </dd>
<dt><code>-u <a href="file://">file://</a><code>pwd</code>/dmrpp/chunked_shuffled_fourD.h5</code> </dt>
<dd><em>The dmr++ file will use this full qualified file URL as its binary data location.</em> </dd>
<dt><code>dmrpp/chunked_shuffled_fourD.h5</code> </dt>
<dd><em>The hdf5 file from which to build the dmr++ file.</em> </dd>
</dl>
<h2><a class="anchor" id="autotoc_md10"></a>
example 2</h2>
<p>Creates a <em>dmr++</em> file (<em>foo.dmrpp</em>) whose binary object URL references an object in Amazon's S3.</p>
<div class="fragment"><div class="line">get_dmrpp -v -d `pwd` -o foo.dmrpp -u https://s3.amazonaws.com/opendap.scratch/data/dmrpp/chunked_fourD.h5  dmrpp/chunked_shuffled_fourD.h5</div>
</div><!-- fragment --> <dl>
<dt><code>-v</code> </dt>
<dd><em>verbose mode</em> </dd>
<dt><code>-d <code>pwd</code></code> </dt>
<dd><em>The data root directory to be used by the BES. In this example it is set to the current directory.</em> <br  />
 </dd>
<dt><code>-o foo.dmrpp</code> </dt>
<dd><em>The dmr++ content will be written to the file foo.dmrpp&lt;</em> </dd>
<dt><code>-u <a href="https://s3.amazonaws.com/opendap.scratch/data/dmrpp/chunked_fourD.h5">https://s3.amazonaws.com/opendap.scratch/data/dmrpp/chunked_fourD.h5</a></code> </dt>
<dd><em>The dmr++ file will use this AWS S3 object URL as its binary data location..</em> <br  />
 </dd>
<dt><code>dmrpp/chunked_shuffled_fourD.h5</code> </dt>
<dd><em>The hdf5 file from which to build the dmr++ file.</em> </dd>
</dl>
<h1><a class="anchor" id="autotoc_md11"></a>
<code>ingest_filesystem</code> - building <em>dmr++</em> files from local files.</h1>
<p>The shell script <code>ingest_filesystem</code> is used to crawl through a branch of the local filesystem, identifying files that match a regular expression (default or supplied), and then attempting to build a <em>dmr++</em> file for each matching file using the <code>get_dmrpp</code> program.</p>
<div class="fragment"><div class="line">Usage: ingest_filesystem [options] </div>
<div class="line"> </div>
<div class="line">Crawl filesystem and make a DMR++ for every dataset matching the</div>
<div class="line">default or supplied regex.</div>
<div class="line"> </div>
<div class="line">The DMR++ is built using the DMR as returned by the HDF5 handler,</div>
<div class="line">using options as set in the bes configuration file used by get_dmrpp.</div>
<div class="line"> </div>
<div class="line">-h: Show help</div>
<div class="line">-v: Verbose: Print the DMR too</div>
<div class="line">-V: Very Verbose: Verbose plus so much more!</div>
<div class="line">-j: Just print the DMR that will be used to build the DMR++</div>
<div class="line">-u: The base endpoint URL for the DMRPP data objects. The assumption</div>
<div class="line">    is that they will be organized the same way the source dataset </div>
<div class="line">    files below the &quot;data_root&quot; (see -d)</div>
<div class="line">    (default: file://${data_root})</div>
<div class="line">-d: The local filesystem root from which the data are to be ingested. </div>
<div class="line">    The filesystem will be searched beginning at this point for files </div>
<div class="line">    whose names match the dataset match regex (see -r).</div>
<div class="line">    (default: $CWD)</div>
<div class="line">-t: The target directory for the dmrpp files. Below this point</div>
<div class="line">    the organization of the data files vis-a-vis their &quot;/&quot; path</div>
<div class="line">    separator divided names will be replicated and dmr++ files placed </div>
<div class="line">    accordingly.</div>
<div class="line">    (default: $CWD)</div>
<div class="line">-r: The dataset match regex used to screen the base filesystem </div>
<div class="line">    for datasets. </div>
<div class="line">    (default: &quot;^.*\\.(h5|he5|nc4)(\\.bz2|\\.gz|\\.Z)?$&quot;)</div>
<div class="line">-f: Use &quot;find&quot; to list all regular files below the data root directory </div>
<div class="line">    and store the list in &quot;${ALL_FILES}&quot; The the dataset match regex is applied</div>
<div class="line">    to each line in ${ALL_FILES} and the matching data files list is placed in</div>
<div class="line">    &quot;${DATA_FILES}&quot;. If this option is omitted the files named in &quot;${DATA_FILES}&quot;</div>
<div class="line">     (if any) will be processed.</div>
<div class="line">    (default: Not Set)</div>
</div><!-- fragment --> <h2><a class="anchor" id="autotoc_md12"></a>
example 1</h2>
<p>In its simplest invocation, <code>ingest_filesystem</code>'s defaults will cause it check for the file <code>./data_files.txt</code>. If found <code>ingest_filesystem</code> will treat every line in <code>./data_files.txt</code> as a fully qualifed path to an <code>hdf5</code>/<code>netcdf-4</code> file for which a <code>dmr++</code> file is to be computed. By default the output tree will be placed in the current working directory. The base end point for the <code>dmr++</code> binary object will be set to the current working directory.</p>
<div class="fragment"><div class="line">ingest_filesystem </div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md13"></a>
example 2</h2>
<p>In this invocation, <code>ingest_filesystem</code> crawls the local filesystem beginning with the CWD every file that matches the default regular expression (<code>^.*\\.(h5|he5|nc4)(\\.bz2|\\.gz|\\.Z)?$</code>) will be treated as an <code>hdf5</code>/<code>netcdf-4</code> file for which a <code>dmr++</code> file is to be computed. The output tree will be placed in a directory called scratch in the current working directory. The base URL for the <code>dmr++</code> binary objects will be set to the current working directory.</p>
<div class="fragment"><div class="line">ingest_filesystem -f -t scratch</div>
</div><!-- fragment --> <dl>
<dt><code>-f</code> </dt>
<dd><em>Use the <code>find</code> command along with the regular expression to traverse the filesystem and locate all of the matching files. These file names are placed, as fully qualified path names, in the file <code>./data_files.txt</code> to be reused or hand edited if needed.</em> <br  />
 </dd>
<dt><code>-t scratch</code> </dt>
<dd><em>Sets name of the directory to which the dmr++ output tree will be written to $CWD/scratch</em> </dd>
</dl>
<h2><a class="anchor" id="autotoc_md14"></a>
example 3</h2>
<p>In this invocation, <code>ingest_filesystem</code> crawls the local filesystem beginning at <code>/usr/share/hyrax</code>. Every file that matches the default regular expression (<code>^.*\\.(h5|he5|nc4)(\\.bz2|\\.gz|\\.Z)?$</code>) will be treated as an <code>hdf5</code>/<code>netcdf-4</code> file for which a <code>dmr++</code> file is to be computed. The output tree will be placed in <code>/tmp/dmrpp</code>. The base URL for the <code>dmr++</code> binary objects will be set to the AWS S3 bucket URL <code><a href="https://s3.amazonaws.com/cloudydap">https://s3.amazonaws.com/cloudydap</a></code> .</p>
<div class="fragment"><div class="line">ingest_filesystem -f -u https://s3.amazonaws.com/cloudydap -d /usr/share/hyrax -t /tmp/dmrpp</div>
</div><!-- fragment --> <dl>
<dt><code>-f</code> </dt>
<dd><em>Use the <code>find</code> command along with the regular expression to traverse the filesystem and locate all of the matching files. These file names are placed, as fully qualified path names, in the file <code>./data_files.txt</code> to be reused or hand edited if needed.</em> <br  />
 </dd>
<dt><code>-u <a href="https://s3.amazonaws.com/cloudydap">https://s3.amazonaws.com/cloudydap</a></code> </dt>
<dd><em>Sets the base URL for the web accessible binary data files to the AWS S3 bucket URL <code><a href="https://s3.amazonaws.com/cloudydap">https://s3.amazonaws.com/cloudydap</a></code> File paths relative to the BES DataRoot will be appended to this URL to form the binary access URL for each dmr++ file. </em> <br  />
 </dd>
<dt><code>-d /usr/share/hyrax</code> </dt>
<dd><em>Sets the BES data root to <code>/usr/share/hyrax</code> for this invocataion. Since the -f option is also present the crawl of the file system will begin here.</em> </dd>
<dt><code>-t /tmp/dmrpp</code> </dt>
<dd><em>Sets the directory to which the dmr++ output tree will be written to: <code>/tmp/dmrpp</code></em> </dd>
</dl>
<h1><a class="anchor" id="autotoc_md15"></a>
<code>ingest_s3bucket</code> - building <em>dmr++</em> files from files held in S3.</h1>
<p>The shell script <code>ingest_s3bucket</code> utilizes the AWS CLI to list the contents of an S3 bucket. The name of each object in the bucket is checked against either the defaukt or user supplied regex. Each matching file is retrieved from S3 and then a <em>dmr++</em> is built from the retrived data object. Once the <em>dmr++</em> file is built the downloaded object is deleted unless otherwise instructed. The code relies on the AWS CLI being installed and configured using the <code>aws configure</code> command (or it's equivalent).</p>
<div class="fragment"><div class="line"> Usage: ingest_s3bucket [options] </div>
<div class="line"> </div>
<div class="line"> List an AWS S3 bucket and make a DMR++ for every dataset matching the</div>
<div class="line"> default (or supplied) regex.</div>
<div class="line"> </div>
<div class="line"> The DMR++ is built using the DMR as returned by the HDF5 handler,</div>
<div class="line"> using options as set in the bes configuration file used by get_dmrpp.</div>
<div class="line">  </div>
<div class="line"> -h: Show help</div>
<div class="line"> -v: Verbose: Print the DMR too</div>
<div class="line"> -V: Very Verbose: Verbose plus so much more. Your eyes will water from</div>
<div class="line">     the scanning of it all.</div>
<div class="line"> -j: Just print the DMR that will be used to build the DMR++</div>
<div class="line"> -s: The endpoint URL for the S3 datastore. </div>
<div class="line">     (default: https://s3.amazonaws.com)</div>
<div class="line"> -b: The S3 bucket name. </div>
<div class="line">     (default: cloudydap)</div>
<div class="line"> -d: The &quot;local&quot; filesystem root for the downloaded data. </div>
<div class="line">     (default: ./s3_data/bucket_name})</div>
<div class="line"> -t: The target directory for the dmrpp files. Below this point</div>
<div class="line">     the structure of the bucket objects vis-a-vis their &quot;/&quot; path</div>
<div class="line">     separator divided names will be replicted and dmr++ placed into</div>
<div class="line">     it accordingly.</div>
<div class="line">     (default: $CWD)</div>
<div class="line"> -f: Retrieve object list from S3 bucket into the list file for the bucket,</div>
<div class="line">     apply the dataset match regex to the object names to create</div>
<div class="line">     the data files list. If this is omitted the files named in an </div>
<div class="line">     exisiting bucket list file (if any) will be processed.</div>
<div class="line">     (default: Not Set)</div>
<div class="line"> -r: The dataset match regex used to screen the filenames </div>
<div class="line">     for matching datasets. </div>
<div class="line">     (default: `^.*\\.(h5|he5|nc4)(\\.bz2|\\.gz|\\.Z)?$`)</div>
<div class="line"> -k: Keep the downloaded datafiles after the dmr++ file has been </div>
<div class="line">     created. Be careful! S3 buckets can be quite large!</div>
<div class="line"> </div>
<div class="line">Dependencies:</div>
<div class="line">This script requires that:</div>
<div class="line"> - The bes installation directory is on the PATH.</div>
<div class="line"> - The AWS Commandline Tools are installed and on the path.</div>
<div class="line"> - The AWS Commandline Tools have been configured for this user with</div>
<div class="line">   AWS access_key_id and aws_secret_access_key that have adequate permissions</div>
<div class="line">   to access the target AWS S3 bucket.</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md16"></a>
example 1</h2>
<div class="fragment"><div class="line">ingest_s3bucket </div>
</div><!-- fragment --><p>In its simplest invocation, <code>ingest_s3bucket</code>'s defaults will cause it check for the file <code>./s3_cloudydap_data_files.txt</code>. (It looks for this file because the default bucket name is <code>cloudydap</code> and the software caches bucket information in the files named in the patterns <code>s3_BUCKETNAME_all_files.txt</code> <code>s3_BUCKETNAME_data_files.txt</code>. Changing the bucket name will change the name of the file information files accordingly). If the file is found, <code>ingest_s3bucket</code> will treat the 4th column of every line in <code>./s3_cloudydap_data_files.txt</code> as a relative path to an <code>hdf5</code>/<code>netcdf-4</code> file in the default bucket (<code>cloudydap</code>) for which a <code>dmr++</code> file is to be computed. By default the output tree will be placed in the current working directory. The base end point for the <code>dmr++</code> binary object will be set the URL of the S3 binary file that was used to create the <code><a href="https://s3.amazonaws.comdmr++">https://s3.amazonaws.comdmr++</a></code> file.</p>
<h2><a class="anchor" id="autotoc_md17"></a>
example 2</h2>
<p>In this example we have <code>ingest_s3bucket</code> locate all the matching data files in the S3 bucket <code>opendap.scratch</code>, store the downloaded data files in <code>/tmp/s3_scratch</code>, and place the resulting dmr++ files in <code>/usr/share/hyrax</code>.</p>
<div class="fragment"><div class="line">ingest_s3bucket -v -f -b opendap.scratch -d /tmp/s3_scratch -t /usr/share/hyrax </div>
</div><!-- fragment --> <dl>
<dt><code>-v</code> </dt>
<dd><em>verbose mode</em> </dd>
<dt><code>-f</code> </dt>
<dd><em>Use the <code>find</code> command along with the regular expression to traverse the object names retrieved from S3 and locate all of the matching files. These file names saved in the file <code>./s3_BUCKETNAME_data_files.txt</code> to be reused or hand edited if needed.</em> </dd>
<dt><code>-v</code> </dt>
<dd><em>verbose mode</em> </dd>
<dt><code>-b opendap.scratch</code> </dt>
<dd><em>Sets the source S3 bucket name to <code>opendap.scratch</code></em> </dd>
<dt><code>-d /tmp/s3_scratch</code> </dt>
<dd><em>Sets the target directory for the data files downloaded from the S3 bucket to <code>/tmp/s3_scratch</code></em> </dd>
<dt><code>-t /usr/share/hyrax</code> </dt>
<dd><em>Sets the directory to which the dmr++ output tree will be written to: <code> /usr/share/hyrax</code>, the default data directry for Hyrax.</em> </dd>
</dl>
<h1><a class="anchor" id="autotoc_md18"></a>
What To Do</h1>
<ol type="1">
<li>Determine the base URL of the hosting service (AWS S3, Google Cloud Store, Apache httpd, etc) you intend to utilize. For example in S3 you need to know the <em>bucket name</em> and the AWS S3 URL (<a href="https://s3.amazonaws.com">https://s3.amazonaws.com</a>) <br  />
</li>
</ol>
<ol type="1">
<li>If you haven't already done so put your data into the hosting service space (And if you <em>do</em> have it locally don't remove it until the <em>dmr++</em> process is completed!)</li>
</ol>
<ol type="1">
<li>Use the tools discussed below to make one or dmr++ files for your data (you'll need the bucket name and all that from previosuly)</li>
</ol>
<ol type="1">
<li>Place the <em>dmr++</em> files, in any organization desired, into the BES.Catalog.catalog.RootDirectory tree.</li>
</ol>
<ol type="1">
<li>You can now access the remote data by navigating to the location of the <em>dmr++</em> files and access them through the Data REquest Form or the DAP2 and DAP4 protocols.</li>
</ol>
<h1><a class="anchor" id="autotoc_md19"></a>
Previously</h1>
<p>ChangeLog</p>
<p>5/25/18</p>
<ul>
<li>Added *.bescmd files for a number of new test files so that we can tell if the hdf5 handler can read these files. If it cannot, then it will be impossible to get a DMR file for input to build_dmrpp to build the DMR++ file for this code. The new test files were made using the mkChunkNewTypes.py script. jhrg</li>
</ul>
<p>4/3/19</p><ul>
<li>Renamed conf files to something less tedious, bes.hdf5.cf.conf(.in)</li>
<li>Removed bes.hdf5.cf.conf from git as it will now be built.</li>
<li>Created "check-local" and "clean-local" targets that cause the bes.hdf5.cf.conf gile to be built correctly for use with get_dmrpp.sh This all happens when running "make check" </li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_e05d7e2b1ecd646af5bb94391405f3b5.html">modules</a></li><li class="navelem"><a class="el" href="dir_8b1b1558f3f6c1ce351d5be39681f4ac.html">dmrpp_module</a></li><li class="navelem"><a class="el" href="dir_ab69e386f15ed63480a44f1c410a274c.html">data</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
