#-----------------------------------------------------------------------#
# OPeNDAP HDF5 Data Handler BES Module Configuration file               #
#-----------------------------------------------------------------------#

#-----------------------------------------------------------------------#
# Require dap configuration to be loaded first                          #
#-----------------------------------------------------------------------#
BES.Include=dap.conf

#-----------------------------------------------------------------------#
# modules to load, includes data modules and command modules            #
#-----------------------------------------------------------------------#

BES.modules+=h5
BES.module.h5=@bes_modules_dir@/libhdf5_module.so

#-----------------------------------------------------------------------#
# Setting the data information
#-----------------------------------------------------------------------#

# The TypeMatch parameter is a list of handler/module names and a regular
# expression separated by a colon. If the regular expression matches an item,
# then the BES uses the associated handler/module. Each <handler>:<regular
# expression> pair is followed by a semicolon. This is used when creating
# containers in the BES (the 'set container' command). The example regular
# expression says to use the 'h4' handler for any file with an extension of
# 'hdf', 'HDF' or 'eos' which may also end in '.gz' or '.bz2'. In the latter
# case the file will be treated as a compressed file.

# BES.Catalog.catalog.TypeMatch=nc:.*\.(nc|NC)(\.gz|\.bz2|\.Z)?$;h4.*\.(hdf|HDF|eos)(\.gz|\.bz2|\.Z)?$;

# To test your TypeMatch regular expression you can use besregtest as
# follows:

# % besregtest type # "nc:.*\.nc$;nc:.*\.nc\.gz$;" fnoc1.nc
# expression ".*\.(nc|NC)(\.gz|\.bz2|\.Z)?$" matches exactly, type = nc

BES.Catalog.catalog.TypeMatch+=h5:.*\.(HDF5|h5|he5)(\.bz2|\.gz|\.Z)?$;

#-----------------------------------------------------------------------#
# HDF5 handler specific parameters: 
#-----------------------------------------------------------------------#
# Setting H5.IgnoreUnknownTypes to true will cause this handler to ignore
# 64-bit integer types (the only HDF5 it will not process). The default
# value of false causes the handler to return an error to the client 
# that explains that 64-bit types are not supported. Variables of the 
# ignored types simply don't show up in the output.
#
# H5.IgnoreUnknownTypes = true

#
# EnableCF: Handle HDF data to follow the CF conventions
#   (true,yes|false,no, defaults to false)
# Since most centers  would like to handle HDF5 data that follows CF now,
# I set the EnableCF to be true, KY 2011-8-4
#
H5.EnableCF=true

# The following keys only work when H5.EnableCF is set to true.
# ######################################
#
#
# When this key is set to true, HDF5 file ID is passed from metadata to data
# services. This may improve performance. However, it may cause NcML module
# fail to access different granules. So set this key to false by default.
H5.EnablePassFileID=false

# ECS Struct metadata attribute is not mapped to DAP
# The handler makes metadata to follow CF based on this attribute
H5.DisableStructMetaAttr=true

# HDF5 group or dataset(variable) path always start with a '/'. When the CF naming rule is applied,
# the first '/' is always changes to "_". This is not necessary and may potentially confuse with
# CF predefined attributes(_FillValue e.g.). 
# So by keeping the following key's value be 'false', the leading underscore of a variable name
# or a group path in DAS are removed. For example, a variable path /a/b will be changed to a_b rather than _a_b.
# One can set this BES key be true to keep the leading underscore in the variable name.
# Note this key only applies to general HDF5 products. 
# The leading underscore in a variable name is always stripped off for some NASA HDF5 products and netCDF-4-like HDF5 products.
H5.KeepVarLeadingUnderscore=false

# When this key is set to true, the handler will check if
# there are name clashings among variables and attributes. 
# For NASA HDF5 and HDF-EOS5 products, we don't see any
# name clashings for variables and attributes. In fact,
# unlike HDF4, it is very rare to have name clashing for HDF5.
# So to reduce performance overhead, we set this key to false by default. 
# Users can set this key to true if it becomes necessary.
H5.EnableCheckNameClashing=false

# When this key is set to true, the original path of the HDF5 objects is
# kept as an attribute. Users can set this key to false if users don't
# care about the absolute path of object names. Performance may get improved.
H5.EnableAddPathAttrs=true


# We find netCDF java has a string size limit(currently 32767). If an HDF5 string size
# is greater than this limit, visualization tools(Panoply etc.) that depend on
# the netCDF Java may not open the HDF5 file. So this key is set to be true to
# skip the HDF5 string of which size is greater than 32767. Users should set this
# key to false if that long string information is necessary or visualization clients
# are not used.
H5.EnableDropLongString=true

# We find that occassionally NASA HDF5 products may have the attribute_FillValue datatype 
# dfferent than the variable datatype. This violates the CF conventions. So the handler
# corrects the FillValue datatype to be the corresponding variable datatype. However, the
# original value of the fillvalue may fall out of the range of the variable datatype.
# An example, var dtype: 'unsigned char';  original fillvalue dtype: 'signed char';
# original fill value: -127 is out of the range of "unsigned char". 
# If such a case occurs, we believe this is a data producer's mistake and should fail the service
# and let the data center reports this issue back to the data producer. 
# However, this may only occur for one or two variables and the data center may not 
# want to discontinue the data service. So we provide the following BES keys to give the
# flexibility to the data center to continue the service and may use NcML to patch the 
# wrong fillvalue until the data producer corrects it in the new release.
# By default, the key FillValueCheck is true. If the fillvalue is out of the range of the variable type, 
# DAP service stops. 
# **To ignore the fillvalue check**, set this key to false. The service runs normally but
# the _Fillvalue of some variables may be wrong. netCDF-Java clients may not access the data correctly.
H5.EnableFillValueCheck=true


# This BES key must be set to false for the real service. Set it to true 
# will generate a DAS output that lists the ignored HDF5 objects and attributes
# during the mapping from HDF5 to DAP2.
# Also this key should only be used when the H5.EnableCF key is set to true.
H5.CheckIgnoreObj=false

# Caching 
# 1. Caching DAP metadata responses. 
# The HDF5 handler can cache (in memory)DDS,DAS and DMR 
# responses it builds. If the H5.MetaDataMemCacheEntries value is zero, the cache
# is turned off. Setting the H5.MetaDataMemCacheEntries to a value greater than
# zero enables caching DDS,DAS and DMR reponses in memory. The cache
# uses a LRU policy for purging old entries; tune its behavior by
# changing the value and the CachePurgeLevel value below. Note that
# this feature is on by default.

H5.MetaDataMemCacheEntries=400


# 2. Caching the data values of HDF5 coordinate variables or specific variables.
# The HDF5 handler also provides a way for the data service agents to 
# cache the data values of coordinate variables or specific variables.
# WARNING: 
# 1) Since this is an advanced feature, we turn off this feature by default.
# Advanced users should read the description and change the H5.LargeDataMemCacheEntries and
# H5.SmallDataMemCacheEntries to an integer value greater than 0. 
# 2) This feature only takes effect when the EnableCF key is set to true.
#
# 2.1 Caching the latitude/longitude coordinate variables and specific data variables
#
# Compared with other coordinate variables, arrays to store latitude/longitude are usually large 
# and arrays to store data variables in the memory cache are also relatively large.
# So we use the BES key name H5.LargeDataMemCacheEntries .
# change the following line to something like H5.LargeDataMemCacheEntries=20 if using this feature.
H5.LargeDataMemCacheEntries=0
#H5.LargeDataMemCacheEntries=20

#
# By turning on the H5.LargeDataMemCacheConfig key to be true, one can provide a configuration file 
# to tell the handler whether and how one wants to store the latitude/longitude and other variable values.
# 
# BES key H5.LargeDataMemCacheConfig, H5.DatacachePath, H5.LargeDataMemCacheFileName should be used together
# to tune this feature. 
# 
# H5.DataCachePath tells the handler where the configuration file is located. It should be a full path of
# a directory (such as /tmp) in a server Hyrax is installed.
#
# H5.LargeDataMemCacheFileName provides the configuration file name(such as ldatamem.conf) that the handler can read.
# The configuration file is a pure text file. 
# Let's call the configuration file ldata.conf.
# The information in the file should be something like:
# 1 cache-ll
# 0 no-cache-ll
# 2 "/cache-ll/swath_1_3d_2x2yz.h5/HDFEOS/SWATHS/Swath/Data Fields/Temperature" 
#
# The first character of every line should always be a number: one of {0,1,2}. The handler will ignore
# the whole line if the first character at each line is not {0,1,2}. 
# These numbers serve as flags to tell the handler how to handle the data variables.
# After the number, an empty space should be followed, after the empty space, a string list can be 
# provided with the space as common separator. 
# 
# Description of each case
# A) Case 1: Flag =1 
# Many NASA grid files of the same product share the same latitude and longitude. So we may only
# cache one latitude/longitude for all the files of the same product. To achieve this,  
# For the line starting with number 1, one can specify one directory name where the latitude/longitude are shared
# either under this directory or under one of the offspring directories of this directory.
# In other words, for all products that the full path of the file name includes that directory qualifies 
# for this case.
# For example, two grids files mygrid1.h5 and mygrid2.h5 share the same latitude and longitude.
# They are located in under the /cache-ll/foo. The full path for the filenames are 
# /cache-ll/foo/mygrid1.h5 and /cache-ll/foo/mygrid2.h5.
# One can specify  "1 cache-ll" at a line in the ldata.conf.  
# The handler will just store one pair of latitude/longitude for all file paths that include cache-ll.
# ** Currently only one directory name can be specified. **
#
# B) Case 2: Flag = 0
# Some NASA swath files have 2-D latitude/longitude coordinate variables that are not appropriate to 
# store in the memory cache because potentially  hundreds or thousands of relatively large latitude/longitude
# arrays stored in the array may cause frequent purging or thrashing of memory caches. So with this 
# flag on, one can specify which directory 

H5.LargeDataMemCacheConfig=true

#H5.DataCachePath= path to store the data memcache configure file or the data disk cache configure file, apply to both small size or large size memory data cache or future disk cache
H5.DataCachePath=/opt/tmp
H5.LargeDataMemCacheFileName=ldatamem.conf


H5.SmallDataMemCacheEntries  = 400

#H5.SmallDataMemCacheConfig=true

#H5.DataDiskCache=true (future version)


#H5.SmallDataMemCacheFileName=yourownname
#H5.SmallDataMemCacheFileName=sdatamem.conf(future version)
#H5.LargeDataMemCacheFileName=yourownname

#H5.DataDiskCacheFileName=(future version)


# The H5.CachePurgeLevel key determines how much of the in-memory cache is
# removed when it is purged. The value 0.2 (the default) configures the
# software to remove the oldest 20% of items from the cache. You do not
# need to edit this to use the cache since 0.2 is the default value.

# H5.CachePurgeLevel = 0.2

