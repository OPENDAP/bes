$Id$

Updated for version 1.3.0

--------------------------------------------------------------------
BUILDING THE SOFTWARE
REQUIREMENTS
NOTES
--------------------------------------------------------------------

This file is provided to give a detailed instruction on customizing
dap_h5_handler so that it will serve NASA AURA EOS5 GRID data in a way that
can be used with the existing visualization clients(e.g. Ferret and GrADS)
that follow strict CF convention.
   
BUILDING THE SOFTWARE

1) Type `./configure --enable-cf --enable-short-path' at the system
   prompt. On some systems you may have to type `sh configure
   --enable-cf --enable-short-path.' If you want this part of the
   server to install someplace other than /usr/local/bin, use --prefix
   to change the prefix from the default "/use/local/."

   If you don't need to serve these data, then you can omit these options
   when you call configure.

2) Type `make' to build the handler.

3) Install the server components in $prefix by running `make install.'

4) Type 'make bes-conf' to run the bes-hdf5-data.sh script which
   inserts the handler in the bes.conf file and adds test data to
   $prefix/share/hyrax/data.

For very detailed instructions on building the software, please see 

   http://hdfdap.hdfgroup.uiuc.edu:8080/install.html


Building from Our SVN Repository

  If you are building from a SVN checkout, run 'autoreconf --verbose' before
  './configure; make'. If you try to run autoconf, etc., by hand and wind up
  with build files that don't work, use 'autoreconf --force --verbose'. Once
  autoreconf has made the configure and Makefile.in files, do ./configure;
  make; make install as outlined above.


REQUIREMENTS

  o You need the libdap library version 3.9.0 to build and install this
    software. If you're using Linux, this means either building form source
    or using the libdap and libdap-devel RPM packages, once they are
    available. 

  o You need a recent(version 1.6.6 or above) copy of HDF5. 
    Use --with-hdf5 to specify where your hdf5 distribution is located 
    if configure cannot find it on its own.
    See './configure --help' for more info.

  o If you're planning on using this with Hyrax, version 1.5, you'll need
    version 3.7.0 of the BES software.

NOTES

  o About CF option 

    - This is an experimental option to support visualization clients
      that follow CF convention. For details, please see technical
      notes on the web.

      http://hdfdap.hdfgroup.uiuc.edu:8080/cf.html

  o This handler will hide dataset that has a name longer than 15
    characters from DAS/DDS output. That means, some dataset won't be
    accessible and can't be seen through visualization clients. You
    can relax this requirement by modifying h5dds.cc near line 602:

    #ifdef CF 
     if(varname.length() > 15)
        return;   
    #endif  

    Feel free to change it to bigger number to see if your favorite
    client can handle it. However, it's safer to restrict it to 15 to
    serve a wide variety of visualization clients.

  o EOS	Grid Generation
    - EOS Grid generation must be enabled;otherwise, there's no point 
      using visualization clients at all.
      This is default configuration option so do not disable it by
      supplying "--use_eos_grid=no".

  o EOS Metadata Parsing
    - The "--enable-cf" option neither parses nor generate Metadata in DAS
      since most clients can't handle such long string.

  o Short Path Name

    - By default, full path names that have group structure information  
      are preserved in the dataset variable names. You can shorten them by 
      using "--enable-short-path=yes" configuration option.
	
  o Dimension name translation

   EOS data use non-standard name like XDim and YDim and they must be
   renamed to follow CF convention.

   In H5EOS.cc near line 313, there's a function that performs
   renaming. You can modify existing entries or add new entries if
   necessary. For example, "nCandidate" in EOS doesn't match the
   concept of "lev" in CF exactly but it's useful for displaying L2G
   EOS data since clients already know the dimension "lev".

	const char* H5EOS::get_CF_name(char* eos_name)
	{
	  string str(eos_name);

	  DBG(cerr << ">get_CF_name:" << str << endl);
	  // <hyokyung 2007.08. 2. 14:25:58>  
	  eos_to_cf_map["MissingValue"] = "missing_value";
	  eos_to_cf_map["Units"] = "units";
	  eos_to_cf_map["XDim"] = "lon";
	  eos_to_cf_map["YDim"] = "lat";
	  eos_to_cf_map["nCandidate"] = "lev";
	      
	  DBG(cerr << eos_to_cf_map[str] << endl);
	  if(eos_to_cf_map[str].size() > 0){
	    return eos_to_cf_map[str].c_str();
	  }
	  else{
	    return str.c_str();
	  }
	}
    

  o Special DAS Attribute Generation

    This special handler generates some special attributes that don't exist
    in the original EOS data to conform to the CF convention. One good
    example is:

    NC_GLOBAL {
        String title "NASA EOS Aura Grid";
        String Conventions "COARDS, GrADS";
        String dataType "Grid";
        String history "Tue Jan 1 00:00:00 CST 2008 : imported by GrADS Data Server 1.3";
    }
   
    Such extra attributes are generated manually and hard coded. We
    believe some of them may be generated automatically via Metadata
    Parsing but we think it's good to leave it as is for a while since
    there are many variations in EOS L3G data and they're not
    finalized yet. In addition, some visualization clients simply
    don't care while others look for very specific fields.

    Modification is simple and straightforward. In h5das.cc, look for
    a function called add_dimension_attributes() at the bottom of the
    file. Feel free to modify it to correct values or add extra
    attributes to meet your needs.
    
  o Shared dimension generation

    For some clients, it's not sufficient to have map data within the
    grid and map data should be defined outside the Grids. For
    example, this handler will generate arrays in DDS
    
    Float32 lat[lat = 720];
    Float32 lon[lon =1440];

    although they are defined in Grids already like below.

    Grid {
      Array:
        Float32 CloudFraction[lat = 720][lon = 1440];
      Maps:
        Float32 lat[lat = 720];
        Float32 lon[lon = 1440];
    } CloudFraction;
    Grid {
      Array:
        Float32 CloudPressure[lat = 720][lon = 1440];
      Maps:
        Float32 lat[lat = 720];
        Float32 lon[lon = 1440];
    } CloudPressure;

    This may cause a potential conflict problem if two Grids have the same Maps
    variable name but dimensions are different.

    For example,

    Grid {
      Array:
        Float32 CloudFraction[lat = 720][lon = 1440];
      Maps:
        Float32 lat[lat = 720];
        Float32 lon[lon = 1440];
    } CloudFraction;
    Grid {
      Array:
        Float32 CloudPressure[lat = 360][lon = 720];
      Maps:
        Float32 lat[lat = 360];
        Float32 lon[lon = 720];
    } CloudPressure;

    This handler will generate only the shared dimension arrays in the first Grid:

    Float32 lat[lat = 720];
    Float32 lon[lon = 1440];

  o Debugging Aids

    - The OPeNDAP libdap library includes the following debugging aids that
      may be of help to you in developing new applications.

    - DBG: simple program instrumentation -- see the file debug.h distributed
      with libdap (which is installed in the libdap header directory; use
      'config-libdap --cflags' and look at the value if -I).

    - DBG2: more elaborate program instrumentation -- by convention this is
      used for output that is half a page or more, while DEBUG is used for
      single line output.

    - To build with program instrumentation use `--enable-debug=<level>'
      where <level> is 1 or 2.

    - By default, both debug and dbnew are *not* enabled. Thus, if you want
      to build a straight version of the libraries and test code, use
      `./configure'. If you want the extra features, use:

      ./configure --enable-dbnew --enable-debug=2
