
$Id: INSTALL,v 1.7 2000/09/29 15:29:13 tom Exp $

INSTALLING THE HDF-DODS SERVER

  Follow these steps to build and install the HDF DODS server.  Please refer
  to the documentation (see http://unidata.ucar.edu/packages/dods) for a
  list of required software.  The configuration procedure will check whether
  your software can be used to build the system.

  (Before trying to build the system, you should check and see whether there
  already exists a binary distribution for your computer.  Check the dods
  home page for a list of these distributions.  If there is one there,
  download it and unpack it, and skip to step 3.  You will need a copy of
  perl with a version number greater than or equal to 5.001.  Type `perl -v'
  to see the version.)

    1. Type `./configure' at the system prompt. On some systems you may have
       to type `sh configure'.

    2. Type `make' to build the server software, and `make check' to build
       the test software.  You must have DejaGNU, the GNU automated testing
       software, to run the makefile's `check' target.  Type `make install'
       to install it on the DODS tree.  Note that this is *not* the same as
       installing the software in a place where the httpd server can find
       it, so there are a couple more steps.
 
    3. To install the data server, you can use the installServers script in
       the $DODS_ROOT/etc directory.  Before you run this script, determine
       the location of your WWW server's CGI directory.  The DODS server
       software is to be copied into that directory.

    4. The HDF server caches some of its responses to requests. In the past
       this cache was stored in the same directory as the data files being
       served.  However, that caused problems with read-only datasets.  In
       the current version of the HDF server the cache directory is /usr/tmp
       and can be configured by changing the value of the variable
       $cache_dir in the file nph-hdf.

  For information about installing secure DODS servers, see the file
  SECURITY in DODS_ROOT.

  Note that the DODS server scripts use specialized versions of
  several Perl modules, shipped with DODS.  These libraries must be
  in the same directory as the DODS server scripts.  However, if they
  are in the same directory as other scripts that use the standard
  versions of these modules, conflicts will develop.  In this case, it
  may be best to establish a CGI directory just for DODS.

MAKING YOUR DATA AVAILABLE

  Data to be served by the DODS server must either be within the http
  server's document root directory or they must be accessible by links in
  the document root directory tree. To find out which directory is the http
  server's document root, look in the httpd configuration data.

  To access a dataset from your server, you must know how to invoke your CGI
  programs, and know where in the document root tree your data lies.  Though
  there are a couple of different ways to configure a httpd server to handle
  CGI requests, DODS requires your server to use a `CGI directory', where
  all CGI programs are stored in a particular directory.  On most of our
  machines, this directory is called `cgi-bin', and a CGI program is invoked
  like this:

    http://dods.gso.uri.edu/cgi-bin/cgi-program

  With a configuration like this, to make the file `east.coast.hdf'
  available to users it must be either placed within the document root
  directory.  On our example machine, the document root directory is
  /usr/local/spool/http so the file must be moved or copied to that
  directory or one of its subdirectories.  If the server is configured to
  handle links, you might also create a symbolic link in that directory or
  one of its subdirectories to the file.  On our example machine, you would
  put the data in place by typing:

    cp east.coast.hdf /usr/local/spool/http

  Then you can access the data from a remote machine with this URL:

    http://dods.gso.uri.edu/cgi-bin/nph-hdf/east.coast.hdf

  After the machine name (dods.gso.uri.edu) the URL contains the path
  to the DODS data server CGI and that the path to the data (relative to the
  document root directory) *follows* the CGI name.

  If you want to create subdirectories to organize your data, they are just
  added to the URL.  For example, if the `east.coast.hdf' file is in a
  directory called /usr/local/spool/http/data/large-scale, the URL would
  look like this:

    http://dods.gso.uri.edu/cgi-bin/nph-hdf/data/large-scale/east.coast.hdf 

  If you have installed the ascii data service (a CGI program called
  `asciival'), you can check your work with a simple web browser, such as
  netscape, by entering a URL with `.asc' appended:

    http://dods.gso.uri.edu/cgi-bin/nph-hdf/data/large-scale/east.coast.hdf.asc 

  Be careful, this can result in a lot of data.  
